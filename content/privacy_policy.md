# Privacy Policy

This page is to inform you of our policies regarding the collection, use and disclosure of personal information we receive from users of the Site.

## Information Collection and Use
We may ask you to provide us with certain personal identifiable information that can be used to contact or identify you. Personal identifiable information may include, but is not limited to your name and your email address.

## Log Data
Our site does not collect/register any information from you while visiting our Site.

## Cookies
Cookies are files with small amount of data, which may include an anonymous unique identifier. Cookies are sent to your browser from a web site and stored on your computer's hard drive.
Like many sites, we use "cookies" to collect information. You can instruct your browser to refuse all cookies or to indicate when a cookie is being sent.

## Changes To This Privacy Policy
The SEMANTiCS consortium may update this Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on the Site. You are advised to review this Privacy Policy periodically for any changes.

## Clarification on Large Language Model Policy
We follow the guidelines from the Program Chairs about the fair use of Large Language Models (LLMs), which can be found in the main call for papers. Papers that include text generated from a large-scale language model (LLM), such as ChatGPT, are prohibited unless the produced text is presented as a part of the paper's experimental analysis. In essence, the policy expects the following:

* The Large Language Model (LLM) policy for SEMANTiCS 2023 prohibits text produced entirely by LLMs (i.e., "generated"). This does not prohibit authors from using LLMs for editing or polishing the author-written text.
* The LLM policy is largely predicated on the principle of being conservative with respect to guarding against potential issues of using LLMs, including plagiarism.
* The LLM policy applies to SEMANTiCS 2023. We expect this policy to evolve in future conferences as we better understand LLMs and their impacts on scientific publishing.
